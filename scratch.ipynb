{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d8e744-eba7-42a0-b5a6-98f73867a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.models\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f3acdb-c4ea-4ce4-ade1-d8efc72ff59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CSV/train.csv\")\n",
    "test_data = pd.read_csv(\"CSV/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87843f78-caf1-404e-b076-366a9b88e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE_data = pd.get_dummies(data,columns = ['Marital Status','Occupation','Location','Property Type'],prefix=['Marital Status','Occupation','Location','Property Type'])\n",
    "#test data\n",
    "OHE_test_data = pd.get_dummies(test_data,columns = ['Marital Status','Occupation','Location','Property Type'],prefix=['Marital Status','Occupation','Location','Property Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fcc9a0-bb86-402d-beb0-14f7e2379a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_features = []\n",
    "for col in data.columns:\n",
    "    if data[col].isnull().any():\n",
    "        na_features.append(col)\n",
    "        \n",
    "na_numerical_features = []\n",
    "na_categorical_features = []\n",
    "\n",
    "for col in na_features:\n",
    "    if data[col].dtype == 'O':\n",
    "        na_categorical_features.append(col)\n",
    "    else:\n",
    "        na_numerical_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c97023f-e6c7-4586-bb81-0bda96aa3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_mean'] = data['Age'].fillna(data['Age'].mean())\n",
    "data = data.drop('Age_mean',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fcec258-ded6-4e08-a3b2-88b0366f9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in na_numerical_features:\n",
    "    if (data[col].skew() <= 0.5) and (data[col].skew() >= -0.5) :\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "        test_data[col] = test_data[col].fillna(test_data[col].mean())\n",
    "    else:\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "        test_data[col] = test_data[col].fillna(test_data[col].median())\n",
    "\n",
    "for col in na_categorical_features:\n",
    "    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "    test_data[col] = test_data[col].fillna(test_data[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40349f18-affa-44de-afe1-702e354c1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train data\n",
    "OHE_data = pd.get_dummies(data,columns = ['Marital Status','Occupation','Location','Property Type'],prefix=['Marital Status','Occupation','Location','Property Type'])\n",
    "#test data\n",
    "OHE_test_data = pd.get_dummies(test_data,columns = ['Marital Status','Occupation','Location','Property Type'],prefix=['Marital Status','Occupation','Location','Property Type'])\n",
    "\n",
    "\n",
    "\n",
    "#mentioning order for ordinal relationship\n",
    "categories = [\n",
    "    ['High School',\"Bachelor's\",\"Master's\",'PhD'],\n",
    "    ['Basic', 'Comprehensive', 'Premium'],\n",
    "    ['Poor', 'Average', 'Good'],\n",
    "    ['Rarely', 'Monthly', 'Weekly', 'Daily']\n",
    "    ]\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=categories)\n",
    "#train data\n",
    "OHE_data[['Education Level','Policy Type', 'Customer Feedback', 'Exercise Frequency']] = ordinal_encoder.fit_transform(OHE_data[['Education Level','Policy Type', 'Customer Feedback', 'Exercise Frequency']])\n",
    "\n",
    "#test data\n",
    "OHE_test_data[['Education Level','Policy Type', 'Customer Feedback', 'Exercise Frequency']] = ordinal_encoder.fit_transform(OHE_test_data[['Education Level','Policy Type', 'Customer Feedback', 'Exercise Frequency']])\n",
    "\n",
    "#train data\n",
    "OHE_data['Smoking Status'] = np.where(OHE_data['Smoking Status'] == 'Yes',1,0)\n",
    "OHE_data['Gender'] = np.where(OHE_data['Gender'] == 'Male',1,0)\n",
    "\n",
    "#test data\n",
    "OHE_test_data['Smoking Status'] = np.where(OHE_test_data['Smoking Status'] == 'Yes',1,0)\n",
    "OHE_test_data['Gender'] = np.where(OHE_test_data['Gender'] == 'Male',1,0)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "\n",
    "#train data\n",
    "OHE_data[['Age','Annual Income','Number of Dependents','Health Score','Previous Claims','Vehicle Age','Credit Score','Insurance Duration']] = scalar.fit_transform(OHE_data[['Age','Annual Income','Number of Dependents','Health Score','Previous Claims','Vehicle Age','Credit Score','Insurance Duration']])\n",
    "\n",
    "#test data\n",
    "OHE_test_data[['Age','Annual Income','Number of Dependents','Health Score','Previous Claims','Vehicle Age','Credit Score','Insurance Duration']] = scalar.fit_transform(OHE_test_data[['Age','Annual Income','Number of Dependents','Health Score','Previous Claims','Vehicle Age','Credit Score','Insurance Duration']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79af7bd-b142-4202-a79b-77309af95073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        # Define the original categories for Ordinal Encoding\n",
    "        self.ordinal_categories = [\n",
    "            ['High School', \"Bachelor's\", \"Master's\", 'PhD'],  # Education Level\n",
    "            ['Basic', 'Comprehensive', 'Premium'],  # Policy Type\n",
    "            ['Poor', 'Average', 'Good'],  # Customer Feedback\n",
    "            ['Rarely', 'Monthly', 'Weekly', 'Daily']  # Exercise Frequency\n",
    "        ]\n",
    "        \n",
    "        # Initialize encoders and scalers\n",
    "        self.ordinal_encoder = OrdinalEncoder(categories=self.ordinal_categories)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "        # Store original one-hot encoded column names for decoding\n",
    "        self.one_hot_columns = ['Marital Status', 'Occupation', 'Location', 'Property Type']\n",
    "\n",
    "    def inverse_transform(self, df_encoded):\n",
    "        \"\"\"\n",
    "        Reverts the transformations applied to the data to obtain human-readable predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        # 1️⃣ **Inverse Min-Max Scaling** (Numerical Features)\n",
    "        numerical_columns = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                             'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "        df_encoded[numerical_columns] = self.scaler.inverse_transform(df_encoded[numerical_columns])\n",
    "\n",
    "        # 2️⃣ **Inverse Binary Encoding** (`Gender` and `Smoking Status`)\n",
    "        df_encoded['Smoking Status'] = df_encoded['Smoking Status'].map({1: 'Yes', 0: 'No'})\n",
    "        df_encoded['Gender'] = df_encoded['Gender'].map({1: 'Male', 0: 'Female'})\n",
    "\n",
    "        # 3️⃣ **Inverse Ordinal Encoding**\n",
    "        df_encoded[['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']] = \\\n",
    "            self.ordinal_encoder.inverse_transform(df_encoded[['Education Level', 'Policy Type', \n",
    "                                                               'Customer Feedback', 'Exercise Frequency']])\n",
    "\n",
    "        # 4️⃣ **Inverse One-Hot Encoding**\n",
    "        decoded_ohe = self._inverse_one_hot(df_encoded, self.one_hot_columns)\n",
    "        df_encoded = df_encoded.drop(columns=[col for col in df_encoded.columns if any(col.startswith(prefix) for prefix in self.one_hot_columns)])\n",
    "        df_encoded = pd.concat([df_encoded, decoded_ohe], axis=1)\n",
    "\n",
    "        return df_encoded\n",
    "\n",
    "    def _inverse_one_hot(self, df, original_columns):\n",
    "        \"\"\"\n",
    "        Helper function to revert One-Hot Encoding.\n",
    "        \"\"\"\n",
    "        decoded_df = pd.DataFrame()\n",
    "        for col in original_columns:\n",
    "            matched_cols = [c for c in df.columns if c.startswith(col + '_')]\n",
    "            decoded_df[col] = df[matched_cols].idxmax(axis=1).str[len(col) + 1:]\n",
    "        return decoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2b192d-e35f-4e70-b3c4-1fa8560fa96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, train_data):\n",
    "        \"\"\"\n",
    "        Initializes encoders using training data.\n",
    "        \"\"\"\n",
    "        self.ordinal_categories = [\n",
    "            ['High School', \"Bachelor's\", \"Master's\", 'PhD'],  # Education Level\n",
    "            ['Basic', 'Comprehensive', 'Premium'],  # Policy Type\n",
    "            ['Poor', 'Average', 'Good'],  # Customer Feedback\n",
    "            ['Rarely', 'Monthly', 'Weekly', 'Daily']  # Exercise Frequency\n",
    "        ]\n",
    "\n",
    "        # ✅ FIX: Handle unknown categories by encoding them as -1\n",
    "        self.ordinal_encoder = OrdinalEncoder(categories=self.ordinal_categories,\n",
    "                                              handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        \n",
    "        # Fill missing values with a default category before fitting\n",
    "        train_data[['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']] = \\\n",
    "            train_data[['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']].fillna(\"Unknown\")\n",
    "\n",
    "        self.ordinal_encoder.fit(train_data[['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']])\n",
    "        \n",
    "        # Initialize MinMaxScaler & fit on numerical columns\n",
    "        self.scaler = MinMaxScaler()\n",
    "        numerical_columns = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                             'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "        self.scaler.fit(train_data[numerical_columns])\n",
    "\n",
    "        # Store one-hot encoded column prefixes\n",
    "        self.one_hot_columns = ['Marital Status', 'Occupation', 'Location', 'Property Type']\n",
    "        self.ohe_columns = [col for col in train_data.columns if any(col.startswith(prefix) for prefix in self.one_hot_columns)]\n",
    "\n",
    "    def inverse_transform(self, df_encoded):\n",
    "        \"\"\"\n",
    "        Converts encoded predictions back to human-readable values.\n",
    "        \"\"\"\n",
    "        df = df_encoded.copy()  # Avoid modifying original data\n",
    "\n",
    "        # 1️⃣ **Inverse Min-Max Scaling (Numerical Features)**\n",
    "        numerical_columns = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                             'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "        df[numerical_columns] = self.scaler.inverse_transform(df[numerical_columns])\n",
    "\n",
    "        # 2️⃣ **Inverse Binary Encoding (Gender & Smoking Status)**\n",
    "        df['Smoking Status'] = df['Smoking Status'].map({1: 'Yes', 0: 'No'})\n",
    "        df['Gender'] = df['Gender'].map({1: 'Male', 0: 'Female'})\n",
    "\n",
    "        # 3️⃣ **Inverse Ordinal Encoding**\n",
    "        df[['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']] = \\\n",
    "            self.ordinal_encoder.inverse_transform(df[['Education Level', 'Policy Type', \n",
    "                                                       'Customer Feedback', 'Exercise Frequency']])\n",
    "\n",
    "        # 4️⃣ **Inverse One-Hot Encoding**\n",
    "        decoded_ohe = self._inverse_one_hot(df)\n",
    "        df.drop(columns=self.ohe_columns, inplace=True, errors='ignore')\n",
    "        df = pd.concat([df, decoded_ohe], axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _inverse_one_hot(self, df):\n",
    "        \"\"\"\n",
    "        Helper function to revert One-Hot Encoding to original categorical values.\n",
    "        \"\"\"\n",
    "        decoded_df = pd.DataFrame()\n",
    "        for col in self.one_hot_columns:\n",
    "            matched_cols = [c for c in df.columns if c.startswith(col + '_')]\n",
    "            if matched_cols:\n",
    "                decoded_df[col] = df[matched_cols].idxmax(axis=1).str[len(col) + 1:]\n",
    "        return decoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f99f538-ba5e-4284-81d4-027ed10ee64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data (ensure it contains all necessary columns)\n",
    "data = pd.read_csv(\"CSV/train.csv\")  \n",
    "\n",
    "# Initialize the preprocessor with training data\n",
    "preprocessor = DataPreprocessor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ef88f76-d45e-463c-8e24-220685bb08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def transform_input(raw_data, preprocessor):\n",
    "    expected_columns = [\n",
    "        'Age', 'Gender', 'Annual Income', 'Marital Status', 'Education Level', \n",
    "        'Occupation', 'Health Score', 'Location', 'Policy Type', 'Number of Dependents',\n",
    "        'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration', \n",
    "        'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type'\n",
    "    ]\n",
    "\n",
    "    # ✅ Fix: Ensure Input Matches Expected Columns\n",
    "    assert len(raw_data) == len(expected_columns), f\"❌ Expected {len(expected_columns)} values, got {len(raw_data)}\"\n",
    "\n",
    "    # ✅ Create DataFrame with Correct Column Names\n",
    "    df = pd.DataFrame([raw_data], columns=expected_columns)\n",
    "\n",
    "    # ✅ Convert 'Gender' and 'Smoking Status' to Binary\n",
    "    df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    df['Smoking Status'] = df['Smoking Status'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    # ✅ Fix: Apply Ordinal Encoding with `handle_unknown`\n",
    "    ordinal_cols = ['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']\n",
    "    df[ordinal_cols] = preprocessor.ordinal_encoder.transform(df[ordinal_cols])\n",
    "\n",
    "    # ✅ Apply One-Hot Encoding\n",
    "    df = pd.get_dummies(df, columns=['Marital Status', 'Occupation', 'Location', 'Property Type'])\n",
    "\n",
    "    # ✅ Ensure One-Hot Encoded Columns Match Training Data\n",
    "    for col in preprocessor.ohe_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  \n",
    "\n",
    "    # ✅ Convert to Float Before MinMax Scaling\n",
    "    df = df.astype(float)\n",
    "\n",
    "    # ✅ Apply MinMax Scaling\n",
    "    df[preprocessor.scaler.feature_names_in_] = preprocessor.scaler.transform(df[preprocessor.scaler.feature_names_in_])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258a906a-5ea4-4cbd-b28c-f20a10ef3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example input row\n",
    "# input_data = [\n",
    "#     19, 'Female', 10049, 'Married', \"Bachelor's\", 'Self-Employed', \n",
    "#     22.59876067, 'Urban', 'Premium', 2, 17, 372, 5,  \n",
    "#     700,  # ✅ Added Credit Score\n",
    "#     'Poor', 'No', 'Weekly', 'House'\n",
    "# ]\n",
    "\n",
    "# # Transform input for model\n",
    "# encoded_input = transform_input(input_data, preprocessor)\n",
    "\n",
    "# # 🔹 **Pass encoded input to model for prediction**\n",
    "# predicted_premium = model.predict(encoded_input)  # Example: [2900]\n",
    "\n",
    "# # 🔹 **Convert back to human-readable format**\n",
    "# decoded_output = preprocessor.inverse_transform(encoded_input)\n",
    "# decoded_output['Predicted Premium'] = predicted_premium\n",
    "\n",
    "# print(decoded_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f28f9edf-9232-4c60-95cf-e2a71439480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data (ensure it contains all necessary columns)\n",
    "train_data = pd.read_csv(\"CSV/train.csv\")  \n",
    "\n",
    "# Initialize the preprocessor with training data\n",
    "preprocessor = DataPreprocessor(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf6ce7f8-783d-4680-8794-496b8733bee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Missing from input: []\n",
      "❌ Extra in input: []\n",
      "Final Predicted Premium: 2225.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Define expected input columns (excluding 'Policy Start Date')\n",
    "expected_columns = [\n",
    "    'Age', 'Gender', 'Annual Income', 'Marital Status', 'Education Level', 'Occupation', \n",
    "    'Health Score', 'Location', 'Policy Type', 'Previous Claims', 'Vehicle Age', \n",
    "    'Credit Score', 'Insurance Duration', 'Number of Dependents', 'Customer Feedback', \n",
    "    'Smoking Status', 'Exercise Frequency', 'Property Type'\n",
    "]\n",
    "\n",
    "def transform_input(raw_data, ordinal_encoder, scalar, expected_model_columns):\n",
    "    \"\"\"Transforms raw user input into model-ready format.\"\"\"\n",
    "    \n",
    "    assert len(raw_data) == len(expected_columns), f\"❌ Expected {len(expected_columns)} values, got {len(raw_data)}\"\n",
    "\n",
    "    # ✅ Create DataFrame with Correct Column Names\n",
    "    df = pd.DataFrame([raw_data], columns=expected_columns)\n",
    "\n",
    "    # ✅ Ensure categorical columns are strings before encoding\n",
    "    categorical_cols = ['Marital Status', 'Occupation', 'Location', 'Property Type']\n",
    "    df[categorical_cols] = df[categorical_cols].astype(str)\n",
    "\n",
    "    # ✅ Apply One-Hot Encoding\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_cols, \n",
    "                                prefix=categorical_cols)\n",
    "\n",
    "    # ✅ Apply Ordinal Encoding first!\n",
    "    ordinal_cols = ['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']\n",
    "    df_encoded[ordinal_cols] = ordinal_encoder.transform(df_encoded[ordinal_cols])\n",
    "\n",
    "    # ✅ Encode binary columns before reordering\n",
    "    df_encoded['Smoking Status'] = np.where(df_encoded['Smoking Status'] == 'Yes', 1, 0)\n",
    "    df_encoded['Gender'] = np.where(df_encoded['Gender'] == 'Male', 1, 0)\n",
    "\n",
    "    # ✅ Ensure all expected one-hot encoded columns exist\n",
    "    for col in expected_model_columns:\n",
    "        if col not in df_encoded.columns:\n",
    "            df_encoded[col] = 0  # Add missing columns with default value 0\n",
    "\n",
    "    # ✅ Reorder columns to match model training data\n",
    "    df_encoded = df_encoded.reindex(columns=expected_model_columns)\n",
    "\n",
    "    # ✅ Apply MinMax Scaling\n",
    "    numerical_columns_scaled = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                                'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "    df_encoded[numerical_columns_scaled] = scalar.transform(df_encoded[numerical_columns_scaled])\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "# ✅ Example Input Data (Remove 'Policy Start Date')\n",
    "input_data_corrected = [  \n",
    "    40, 'Female', 123751, 'Single', \"Master's\", 'Self-Employed',  \n",
    "    24.9553, 'Suburban', 'Premium', 0, 8, 420, 2, 2, 'Good', 'Yes', 'Rarely', 'Condo'\n",
    "]\n",
    "\n",
    "# ✅ Fit MinMaxScaler\n",
    "scalar = MinMaxScaler()\n",
    "required_columns = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                    'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "scalar.fit(OHE_data[required_columns])\n",
    "\n",
    "# ✅ Fit Ordinal Encoder on Training Data\n",
    "categories = [\n",
    "    ['High School', \"Bachelor's\", \"Master's\", 'PhD'],  # Education Level\n",
    "    ['Basic', 'Comprehensive', 'Premium'],  # Policy Type\n",
    "    ['Poor', 'Average', 'Good'],  # Customer Feedback\n",
    "    ['Rarely', 'Monthly', 'Weekly', 'Daily']  # Exercise Frequency\n",
    "]\n",
    "ordinal_encoder = OrdinalEncoder(categories=categories, handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ordinal_encoder.fit(OHE_data[['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']].astype(str))\n",
    "\n",
    "# ✅ Define expected columns for model input\n",
    "expected_model_columns = [\n",
    "    'Age', 'Gender', 'Annual Income', 'Education Level', 'Health Score', 'Policy Type', \n",
    "    'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration', 'Number of Dependents', \n",
    "    'Customer Feedback', 'Smoking Status', 'Exercise Frequency', \n",
    "    'Marital Status_Divorced', 'Marital Status_Married', 'Marital Status_Single', \n",
    "    'Occupation_Employed', 'Occupation_Self-Employed', 'Occupation_Unemployed', \n",
    "    'Location_Rural', 'Location_Suburban', 'Location_Urban', \n",
    "    'Property Type_Apartment', 'Property Type_Condo', 'Property Type_House'\n",
    "]\n",
    "# print(\"Model expects:\", model.feature_names_in_)\n",
    "# print(\"Input columns:\", encoded_input.columns.tolist())\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Transform input\n",
    "encoded_input = transform_input(input_data_corrected, ordinal_encoder, scalar, expected_model_columns)\n",
    "\n",
    "# ✅ Ensure correct order before prediction\n",
    "encoded_input = encoded_input[[\n",
    "    'Age', 'Gender', 'Annual Income', 'Number of Dependents', 'Education Level', 'Health Score',\n",
    "    'Policy Type', 'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration',\n",
    "    'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Marital Status_Divorced',\n",
    "    'Marital Status_Married', 'Marital Status_Single', 'Occupation_Employed', 'Occupation_Self-Employed',\n",
    "    'Occupation_Unemployed', 'Location_Rural', 'Location_Suburban', 'Location_Urban',\n",
    "    'Property Type_Apartment', 'Property Type_Condo', 'Property Type_House'\n",
    "]]\n",
    "\n",
    "# ✅ Convert to float (important for model compatibility)\n",
    "encoded_input = encoded_input.astype(np.float32)\n",
    "\n",
    "# ✅ Predict premium\n",
    "predicted_premium = model.predict(encoded_input)\n",
    "# print(f\"Final Predicted Premium: {predicted_premium[0]:.2f}\")\n",
    "missing_from_input = [col for col in model.feature_names_in_ if col not in encoded_input.columns]\n",
    "extra_in_input = [col for col in encoded_input.columns if col not in model.feature_names_in_]\n",
    "print(\"❌ Missing from input:\", missing_from_input)\n",
    "print(\"❌ Extra in input:\", extra_in_input)\n",
    "\n",
    "for col in missing_from_input:\n",
    "    encoded_input[col] = 0  # Add missing columns with default 0\n",
    "# ✅ Predict premium\n",
    "predicted_premium = model.predict(encoded_input)\n",
    "print(f\"Final Predicted Premium: {predicted_premium[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aac845ec-c47a-4992-81cc-e2c8c5479c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Gender  Annual Income  Number of Dependents  Education Level  \\\n",
      "0  40.0     0.0       123751.0                   2.0              2.0   \n",
      "\n",
      "   Health Score  Policy Type  Previous Claims  Vehicle Age  Credit Score  ...  \\\n",
      "0     24.955299          2.0              0.0          8.0         420.0  ...   \n",
      "\n",
      "   Marital Status_Single  Occupation_Employed  Occupation_Self-Employed  \\\n",
      "0                    1.0                  0.0                       1.0   \n",
      "\n",
      "   Occupation_Unemployed  Location_Rural  Location_Suburban  Location_Urban  \\\n",
      "0                    0.0             0.0                1.0             0.0   \n",
      "\n",
      "   Property Type_Apartment  Property Type_Condo  Property Type_House  \n",
      "0                      0.0                  1.0                  0.0  \n",
      "\n",
      "[1 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f68d9704-cc58-4301-b8e0-1937fb933da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = OHE_data['Premium Amount']\n",
    "x_train = OHE_data.drop(['Premium Amount', 'id', 'Policy Start Date'], axis=1)\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e1076-9ee8-4c9c-b611-e6caba7742f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load trained model (if saved)\n",
    "# model = pickle.load(open(\"trained_model.pkl\", \"rb\"))\n",
    "\n",
    "y_train = OHE_data['Premium Amount']\n",
    "x_train = OHE_data.drop(['Premium Amount', 'id', 'Policy Start Date'], axis=1)\n",
    "\n",
    "# Train a new XGBoost model (if not loaded)\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# ✅ Example Input Data (Remove 'Policy Start Date')\n",
    "input_data_corrected = [  \n",
    "    40, 'Female', 123751, 'Single', \"Master's\", 'Self-Employed',  \n",
    "    24.9553, 'Suburban', 'Premium', 0, 8, 420, 2, 2, 'Good', 'Yes', 'Rarely', 'Condo'\n",
    "]\n",
    "\n",
    "# Transform input for model\n",
    "encoded_input = transform_input(input_data_corrected, ordinal_encoder, scalar)\n",
    "\n",
    "# ✅ Ensure all required columns exist in `encoded_input`\n",
    "missing_cols = set(x_train.columns) - set(encoded_input.columns)\n",
    "for col in missing_cols:\n",
    "    print(f\"⚠️ Missing column: {col}. Adding with default value 0.\")\n",
    "    encoded_input[col] = 0  # Add missing columns with 0s\n",
    "\n",
    "# ✅ Ensure column order matches training data\n",
    "encoded_input = encoded_input[x_train.columns]\n",
    "\n",
    "# Make Prediction\n",
    "predicted_premium = model.predict(encoded_input)\n",
    "print(f\"Predicted Premium: {predicted_premium[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5653c7a-c06b-4ae6-8bc2-2151381a1c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Evaluation on `test.csv`:\n",
      "✔ Mean Absolute Error (MAE): 3235.71\n",
      "✔ Mean Squared Error (MSE): 11890529.44\n",
      "✔ R² Score: -14.8917\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ✅ Load Test Data\n",
    "test_data = pd.read_csv(\"CSV/train.csv\")\n",
    "\n",
    "# ✅ Define Expected Columns (Excluding 'Policy Start Date')\n",
    "expected_columns = [\n",
    "    'Age', 'Gender', 'Annual Income', 'Marital Status', 'Education Level', 'Occupation', \n",
    "    'Health Score', 'Location', 'Policy Type', 'Previous Claims', 'Vehicle Age', \n",
    "    'Credit Score', 'Insurance Duration', 'Number of Dependents', 'Customer Feedback', \n",
    "    'Smoking Status', 'Exercise Frequency', 'Property Type'\n",
    "]\n",
    "\n",
    "# ✅ Fit MinMaxScaler on Training Data\n",
    "scaler = MinMaxScaler()\n",
    "required_columns = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                    'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "scaler.fit(OHE_data[required_columns])  # Fit using training data\n",
    "\n",
    "# ✅ Fit Ordinal Encoder on Training Data\n",
    "categories = [\n",
    "    ['High School', \"Bachelor's\", \"Master's\", 'PhD'],  # Education Level\n",
    "    ['Basic', 'Comprehensive', 'Premium'],  # Policy Type\n",
    "    ['Poor', 'Average', 'Good'],  # Customer Feedback\n",
    "    ['Rarely', 'Monthly', 'Weekly', 'Daily']  # Exercise Frequency\n",
    "]\n",
    "ordinal_encoder = OrdinalEncoder(categories=categories, handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ordinal_encoder.fit(OHE_data[['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']].astype(str))\n",
    "\n",
    "# ✅ Define Expected Model Columns (Order Matters!)\n",
    "expected_model_columns = [\n",
    "    'Age', 'Gender', 'Annual Income', 'Number of Dependents', 'Education Level', 'Health Score',\n",
    "    'Policy Type', 'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration',\n",
    "    'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Marital Status_Divorced',\n",
    "    'Marital Status_Married', 'Marital Status_Single', 'Occupation_Employed', 'Occupation_Self-Employed',\n",
    "    'Occupation_Unemployed', 'Location_Rural', 'Location_Suburban', 'Location_Urban',\n",
    "    'Property Type_Apartment', 'Property Type_Condo', 'Property Type_House'\n",
    "]\n",
    "\n",
    "\n",
    "# ✅ Apply Transformation to Test Data\n",
    "X_test = transform_input(test_data, ordinal_encoder, scaler, expected_model_columns)\n",
    "\n",
    "# ✅ Convert to float (important for XGBoost)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# ✅ Load Ground Truth Values (Assuming 'Premium Amount' is in Test Data)\n",
    "y_test = test_data['Premium Amount']\n",
    "\n",
    "# ✅ Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ✅ Evaluate Model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"📊 Model Evaluation on `test.csv`:\")\n",
    "print(f\"✔ Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"✔ Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"✔ R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e946f6d-9101-4272-8d9c-b5cc236d91d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Evaluation:\n",
      "✔ Mean Absolute Error (MAE): 637.66\n",
      "✔ Mean Squared Error (MSE): 708317.44\n",
      "✔ R² Score: 0.0521\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Gender: object, Smoking Status: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 117\u001b[0m\n\u001b[0;32m    114\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m encoded_input[X_train_encoded\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Make Prediction\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m predicted_premium \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(encoded_input)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m💰 Predicted Premium: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_premium[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1187\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1188\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1189\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1190\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1191\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1192\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1193\u001b[0m         )\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\xgboost\\core.py:2512\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2510\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m-> 2512\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m   2514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fns)\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\xgboost\\data.py:603\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_pandas_df\u001b[39m(\n\u001b[0;32m    597\u001b[0m     data: DataFrame,\n\u001b[0;32m    598\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    601\u001b[0m     meta: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    602\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[PandasTransformed, Optional[FeatureNames], Optional[FeatureTypes]]:\n\u001b[1;32m--> 603\u001b[0m     pandas_check_dtypes(data, enable_categorical)\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _matrix_meta:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot have multiple columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\xgboost\\data.py:569\u001b[0m, in \u001b[0;36mpandas_check_dtypes\u001b[1;34m(data, enable_categorical)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtypes:\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    564\u001b[0m         (dtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _pandas_dtype_mapper)\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pd_sparse_dtype(dtype)\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (is_pd_cat_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m enable_categorical)\n\u001b[0;32m    567\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pa_ext_dtype(dtype)\n\u001b[0;32m    568\u001b[0m     ):\n\u001b[1;32m--> 569\u001b[0m         _invalid_dataframe_dtype(data)\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_pd_sparse_dtype(dtype):\n\u001b[0;32m    572\u001b[0m         sparse_extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\xgboost\\data.py:356\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    354\u001b[0m type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 356\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Gender: object, Smoking Status: object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ✅ Load Data\n",
    "df = pd.read_csv(\"CSV/train.csv\")  # Change this to your actual dataset\n",
    "\n",
    "\n",
    "# ✅ Drop Unnecessary Columns\n",
    "df = df.drop(['id', 'Policy Start Date'], axis=1)\n",
    "\n",
    "# ✅ Define Categorical & Numerical Columns\n",
    "categorical_cols = ['Marital Status', 'Occupation', 'Location', 'Property Type']\n",
    "ordinal_cols = ['Education Level', 'Policy Type', 'Customer Feedback', 'Exercise Frequency']\n",
    "numerical_cols = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                  'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "\n",
    "# ✅ Define Ordinal Encoding Categories\n",
    "ordinal_categories = [\n",
    "    ['High School', \"Bachelor's\", \"Master's\", 'PhD'],  # Education Level\n",
    "    ['Basic', 'Comprehensive', 'Premium'],  # Policy Type\n",
    "    ['Poor', 'Average', 'Good'],  # Customer Feedback\n",
    "    ['Rarely', 'Monthly', 'Weekly', 'Daily']  # Exercise Frequency\n",
    "]\n",
    "\n",
    "# ✅ Encode Binary Features\n",
    "df['Smoking Status'] = np.where(df['Smoking Status'] == 'Yes', 1, 0)\n",
    "df['Gender'] = np.where(df['Gender'] == 'Male', 1, 0)\n",
    "\n",
    "# ✅ Train-Test Split\n",
    "X = df.drop(columns=['Premium Amount'])  # Features\n",
    "y = df['Premium Amount']  # Target Variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Fit Encoders & Scalers on Training Data\n",
    "ordinal_encoder = OrdinalEncoder(categories=ordinal_categories, handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ordinal_encoder.fit(X_train[ordinal_cols].astype(str))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[numerical_cols])\n",
    "\n",
    "# ✅ Transform Data Function\n",
    "def transform_input(df):\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Apply One-Hot Encoding\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=categorical_cols, prefix=categorical_cols)\n",
    "    \n",
    "    # Apply Ordinal Encoding\n",
    "    df_encoded[ordinal_cols] = ordinal_encoder.transform(df_encoded[ordinal_cols])\n",
    "    \n",
    "    # Apply Scaling\n",
    "    df_encoded[numerical_cols] = scaler.transform(df_encoded[numerical_cols])\n",
    "    \n",
    "    # Ensure all expected columns exist\n",
    "    for col in expected_columns:\n",
    "        if col not in df_encoded.columns:\n",
    "            df_encoded[col] = 0  # Fill missing columns with 0\n",
    "    \n",
    "    # Reorder columns\n",
    "    df_encoded = df_encoded[expected_columns]\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# ✅ Define Expected Columns (After Encoding)\n",
    "expected_columns = [\n",
    "    'Age', 'Gender', 'Annual Income', 'Number of Dependents', 'Education Level', 'Health Score',\n",
    "    'Policy Type', 'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration',\n",
    "    'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Marital Status_Divorced',\n",
    "    'Marital Status_Married', 'Marital Status_Single', 'Occupation_Employed', 'Occupation_Self-Employed',\n",
    "    'Occupation_Unemployed', 'Location_Rural', 'Location_Suburban', 'Location_Urban',\n",
    "    'Property Type_Apartment', 'Property Type_Condo', 'Property Type_House'\n",
    "]\n",
    "\n",
    "# ✅ Preprocess Train & Test Data\n",
    "X_train_encoded = transform_input(X_train)\n",
    "X_test_encoded = transform_input(X_test)\n",
    "\n",
    "# ✅ Train XGBoost Model\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# ✅ Predict on Test Set\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "# ✅ Evaluate Model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"📊 Model Evaluation:\")\n",
    "print(f\"✔ Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"✔ Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"✔ R² Score: {r2:.4f}\")\n",
    "\n",
    "# ✅ Example Input Data (Remove 'Policy Start Date')\n",
    "input_data_corrected = pd.DataFrame([{\n",
    "    'Age': 40, 'Gender': 'Female', 'Annual Income': 123751, 'Marital Status': 'Single',\n",
    "    'Education Level': \"Master's\", 'Occupation': 'Self-Employed', 'Health Score': 24.9553,\n",
    "    'Location': 'Suburban', 'Policy Type': 'Premium', 'Previous Claims': 0, 'Vehicle Age': 8,\n",
    "    'Credit Score': 420, 'Insurance Duration': 2, 'Number of Dependents': 2,\n",
    "    'Customer Feedback': 'Good', 'Smoking Status': 'Yes', 'Exercise Frequency': 'Rarely',\n",
    "    'Property Type': 'Condo'\n",
    "}])\n",
    "\n",
    "# ✅ Transform input for model\n",
    "encoded_input = transform_input(input_data_corrected)\n",
    "\n",
    "# ✅ Ensure column order matches training data\n",
    "encoded_input = encoded_input[X_train_encoded.columns]\n",
    "\n",
    "# Make Prediction\n",
    "predicted_premium = model.predict(encoded_input)\n",
    "print(f\"💰 Predicted Premium: {predicted_premium[0]:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e98b88-4a3b-435d-8f6e-a9d4842c39e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
